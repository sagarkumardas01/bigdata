## Internal table =~ Managed table.
# Use this command to get details about seriaazion and deserialization
     describe formatted table_name
---------------------------------
Parquet Table Storage information
---------------------------------
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
InputFormat:            org.apache.hadoop.mapred.TextInputFormat ----> Parquet Serde
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat ---> Parquet Serde
Compressed:             No
---------------------------------    
create table csv_table
    > (name string,
    > location string
    > )
    > row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
    > with serdeproperties(
    > "separatorChar" = ",",
    > "quoteChar" = "\"",
    > "escapeChar" = "\\"
    > )
    > stored as textfile
    > tblproperties("skip.header.line.count" = "1");
    
    
    RAW DATA
    ---------
    Sagar,"PDP,Odisha"
    Amit,"Banglore,Karnatak"
    --------------------------
    
    JSON File Format
    ---------------------
    file
    ----
    {"name": "Sagar", "id": 100, "Skills":["Hadoop","Python"]}
    
    Download hive catalog jar file if serde file is not imported
     Google search for -> https://repo1.maven.org/maven2/org/apache/hive/hcatalog/hive-hcatalog-core/0.14.0/
     
    #Add jar file into hive shell
    hive> add jar jar file location -> /tmp/hive_class
    hive> add jar /tmp/hive_class/hive-catalog-core-0.14.0.jar
    
    #Download Sales_Order.csv from below link
    
    https://github.com/shashank-mishra219/Hive-Class/blob/main/sales_order_data.csv
    
    
    
   # create csv table for sales data

create table sales_order_data_csv_v1
(
ORDERNUMBER int,
QUANTITYORDERED int,
PRICEEACH float,
ORDERLINENUMBER int,
SALES float,
STATUS string,
QTR_ID int,
MONTH_ID int,
YEAR_ID int,
PRODUCTLINE string,
MSRP int,
PRODUCTCODE string,
PHONE string,
CITY string,
STATE string,
POSTALCODE string,
COUNTRY string,
TERRITORY string,
CONTACTLASTNAME string,
CONTACTFIRSTNAME string,
DEALSIZE string
)
row format delimited
fields terminated by ','
tblproperties("skip.header.line.count"="1")
; 

# load sales_order_data.csv data into above mentioned tables

create table sales_order_data_orc
(
ORDERNUMBER int,
QUANTITYORDERED int,
PRICEEACH float,
ORDERLINENUMBER int,
SALES float,
STATUS string,
QTR_ID int,
MONTH_ID int,
YEAR_ID int,
PRODUCTLINE string,
MSRP int,
PRODUCTCODE string,
PHONE string,
CITY string,
STATE string,
POSTALCODE string,
COUNTRY string,
TERRITORY string,
CONTACTLASTNAME string,
CONTACTFIRSTNAME string,
DEALSIZE string
)
stored as orc;

# copy data from sales_order_data_csv_v1 to sales_order_data_orc


select year_id, sum(sales) as total_sales from sales_order_data_orc group by year_id; 

# here only 1 map and 1 reduce task will get created

In order to change the average load for a reducer (in bytes):                                                                                 
  set hive.exec.reducers.bytes.per.reducer=<number>                                                                                           
In order to limit the maximum number of reducers:                                                                                             
  set hive.exec.reducers.max=<number>                                                                                                         
In order to set a constant number of reducers:                                                                                                
  set mapreduce.job.reduces=<number> 
  
 # change number of reducers to 3
 
 set mapreduce.job.reduces=3;
 create table sales_order_grouped_orc_v1 stored as orc as select year_id, sum(sales) as total_sales from sales_order_data_orc group by ye
ar_id;

# after creating the table, check the number of files in hdfs location
hive> hadoop fs -ls /user/hive/warehouse/hive_class_b1.db/sales_order_grouped_orc_v1

-rwxrwxrwx   1 cloudera supergroup        328 2022-10-27 20:33 /user/hive/warehouse/hive_class_b1.db/sales_order_grouped_orc_v1/000000_0
-rwxrwxrwx   1 cloudera supergroup        305 2022-10-27 20:33 /user/hive/warehouse/hive_class_b1.db/sales_order_grouped_orc_v1/000001_0
-rwxrwxrwx   1 cloudera supergroup        305 2022-10-27 20:33 /user/hive/warehouse/hive_class_b1.db/sales_order_grouped_orc_v1/000002_0


# change number of reducers to 2
 
 set mapreduce.job.reduces=2;
 create table sales_order_grouped_orc_v2 stored as orc as select year_id, sum(sales) as total_sales from sales_order_data_orc group by ye
ar_id;

# after creating the table, check the number of files in hdfs location

Partition
---------
1 - Static partition

2 - Dynamic partition

create table sales_data_static_part                                                                                                     
    > (                                                                                                                                       
    > ORDERNUMBER int,                                                                                                                        
    > QUANTITYORDERED int,                                                                                                                    
    > SALES float,                                                                                                                            
    > YEAR_ID int                                                                                                                             
    > )                                                                                                                                       
    > partitioned by (COUNTRY string); 
    
# set this property if doing static partition
set hive.mapred.mode=strict; 
    
    
# load data in static partition

insert overwrite table sales_data_static_part partition(country = 'USA') select ordernumber,quantityordered,sales,year_id from sales_ord
er_data_orc where country = 'USA';

#Check in hdfs location you will find one file will be created there as partition was for one specific USA

[cloudera@quickstart ~]$ hadoop fs -ls /user/hive/warehouse/hive_class_b1.db/sales_data_static_part
Found 1 items
drwxrwxrwx   - cloudera supergroup          0 2022-10-27 20:51 /user/hive/warehouse/hive_class_b1.db/sales_data_static_part/country=USA


# set this property for dynamic partioning
set hive.exec.dynamic.partition.mode=nonstrict; 

hive> create table sales_data_dynamic
    > (
    > ORDERNUMBER int,
    > QUANTITYORDERED int,
    > SALES float
    > )
    > partitioned by (COUNTRY string);



# multilevel partition

create table sales_data_dynamic_multilevel_part_v1                                                                                      
    > (
    > ORDERNUMBER int,                                                                                                                        
    > QUANTITYORDERED int,                                                                                                                    
    > SALES float                                                                                                                             
    > )
    > partitioned by (COUNTRY string, YEAR_ID int); 
    
# load data in multilevel partitions

insert overwrite table sales_data_dynamic_multilevel_part_v1 partition(country,year_id) select ordernumber,quantityordered,sales,country
,year_id from sales_order_data_orc;
    
    
    
    
